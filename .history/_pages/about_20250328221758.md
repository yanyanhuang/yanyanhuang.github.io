---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I'm currently a second year PhD student at [The University of Hong Kong](https://www.hku.hk/), supervised by [Prof. Lequan Yu](https://yulequan.github.io/). I obtained my MPhil degree in [Zhejiang University](https://www.zju.edu.cn/) in 2023 and the B.Eng degree in [Harbin Institute of Technology](https://www.hit.edu.cn/) in 2020.

My research lies at the intersection of artificial intelligence and healthcare. I am dedicated to designing advanced machine learning algorithms for healthcare and medical image analysis. Currently, I mainly focus on deep learning algorithms for whole slide image analysis.

I am also a machine learning competition enthusiast and a [Kaggle Competitions Master](https://www.kaggle.com/rock139) (ü•á√ó2, ü•à√ó2).

<!-- My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>). -->


<div class="news-wrapper">
  <h1>üì∞ News</h1>
  <div class="news-box">
    <ul>
      <li><i>2024.09</i> - üéâ Our paper on new framework for computational pathology has been accepted by <a href="https://ieeexplore.ieee.org/abstract/document/10706928">IEEE Transactions on Medical Imaging (TMI)</a>!</li>
      <li><i>2024.09</i> - üéâ Our work on pathology foundation model enhancement has been accepted by <a href="https://openreview.net/pdf?id=dwYekpbmYG">NeurIPS 2024</a>!</li>
      <li><i>2024.08</i> - üéâ Our research on low-dose PET image denoising has been accepted by <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841524002317">Medical Image Analysis (MIA)</a>!</li>
      <li><i>2024.08</i> - üéâ Our study on brain aging patterns has been accepted by <a href="https://www.sciencedirect.com/science/article/abs/pii/S0278584624001568">Progress in Neuro-Psychopharmacology and Biological Psychiatry (PNP)</a>!</li>
      <li><i>2023.07</i> - üéØ Our work on continual learning for WSI analysis has been accepted by <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Huang_ConSlide_Asynchronous_Hierarchical_Interaction_Transformer_with_Breakup-Reorganize_Rehearsal_for_Continual_ICCV_2023_paper.html">ICCV 2023</a>!</li>
      <li><i>2023.07</i> - üéØ Our research on brain age estimation has been accepted by <a href="https://www.sciencedirect.com/science/article/pii/S1566253523002476">Information Fusion</a> (Impact Factor: 17.56)!</li>
      <li><i>2023.05</i> - üèÜ Achieved <strong>Gold Medal</strong> (Ranked 7th out of 1,165 teams) in <a href="https://www.kaggle.com/competitions/asl-signs">Google's "Isolated Sign Language Recognition"</a> Competition!</li>
      <li><i>2023.02</i> - üéØ Our innovative approach in low-dose CT and low-dose PET image denoising has been accepted by <a href="https://www.sciencedirect.com/science/article/pii/S1361841523000488">Medical Image Analysis (MIA)</a>!</li>
      <li><i>2023.02</i> - üéØ Our research on Gait Recognition has been accepted by <a href="https://ieeexplore.ieee.org/abstract/document/10096835">ICASSP 2023</a>!</li>
      <li><i>2022.09</i> - üèÜ Secured <strong>Gold Medal</strong> (Ranked 4th out of 1,175 teams) in <a href="https://www.kaggle.com/competitions/hubmap-organ-segmentation">Kaggle's "Hacking the Human Body"</a> Competition!</li>
    </ul>
  </div>
</div>

<!-- # üìù Publications -->
# Publications

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024</div><img src='images/neurips24_cate.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Free Lunch in Pathology Foundation Model: Task-specific Model Adaptation with Concept-Guided Feature Enhancement](https://openreview.net/pdf?id=dwYekpbmYG)

**Yanyan Huang**, Weiqin Zhao, Yihang Chen, Yu Fu, Lequan Yu.

*Conference on Neural Information Processing Systems (****NeurIPS****), 2024*

We introduce a novel approach for efficient task-specific adaptation in pathology foundation models. Our method leverages concept-guided feature enhancement to achieve superior performance while maintaining computational efficiency. The framework demonstrates significant improvements across various pathology analysis tasks.
</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TMI</div><img src='images/tmi_pam.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Unleash the Power of State Space Model for Whole Slide Image with Local Aware Scanning and Importance Resampling](https://ieeexplore.ieee.org/abstract/document/10706928)

**Yanyan Huang**, Weiqin Zhao, Yu Fu, Lingting Zhu, and Lequan Yu.

<!-- ***TMI*** -->
*IEEE Transactions on Medical Imaging (****TMI****), 2024*

This paper introduces a new Pathology Mamba (PAM) for more accurate and robust WSI analysis. It includes three carefully designed components to tackle the challenges of enormous image size, the utilization of local and hierarchical information, and the mismatch between the feature distributions of training and testing during WSI analysis.
</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2023</div><img src='images/iccv2023.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[ConSlide: Asynchronous Hierarchical Interaction Transformer with Breakup-Reorganize Rehearsal for Continual Whole Slide Image Analy](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_ConSlide_Asynchronous_Hierarchical_Interaction_Transformer_with_Breakup-Reorganize_Rehearsal_for_Continual_ICCV_2023_paper.html)

**Yanyan Huang**, Weiqin Zhao, Shujun Wang, Yu Fu, Yuming Jiang, Lequan Yu.

<!-- ***ICCV 2023*** -->
*International Conference on Computer Vision (****ICCV****), poster, 2023*

Propose the first continual learning framework for WSI analysis, named ConSlide, to tackle the challenges of enormous image size, utilization of hierarchical structure, and catastrophic forgetting by progressive model updating on multiple sequential datasets. 
<!-- It contains three key components: the Hierarchical Interaction Transformer (HIT), the Breakup-Reorganize (BuRo) rehearsal method, and the nested cross-scale similarity learning (CSSL) module. -->
</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Information Fusion</div><img src='images/otfpf.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[OTFPF: Optimal Transport Based Feature Pyramid Fusion Network for Brain Age Estimation](https://www.sciencedirect.com/science/article/pii/S1566253523002476)

Yu Fu$^{*}$, **Yanyan Huang$^{*}$**, Zhe Zhang, Shunjie Dong, Le Xue, Meng Niu, Yunxin Li, Zhiguo Shi, Yalin Wang, Hong Zhang, Mei Tian, Cheng Zhuo.

<!-- ***Information Fusion*** -->
*Information Fusion (****IF****), 2023*

Propose the Optimal Transport based Feature Pyramid Fusion (OTFPF) network for estimating brain age using T1 MRIs. Experimental results utilizing a dataset of 12,909 MRIs from individuals aged 3‚Äì97 years demonstrate the accurate estimation of brain age by the OTFPF network.
<!-- , achieving a mean absolute error (MAE) of 1.846, Pearson's correlation coefficient (PCC) of 0.9941, and Spearman's rank correlation coefficient (SRCC) of 0.9802. -->
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICASSP 2023</div><img src='images/hdnet.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[HDNet: Hierarchical Dynamic Network for Gait Recognition using Millimeter-Wave Radar](https://ieeexplore.ieee.org/abstract/document/10096835)

**Yanyan Huang**, Yong Wang, Kun Shi, Chaojie Gu, Yu Fu, Cheng Zhuo, Zhiguo Shi.

<!-- ***ICASSP 2023*** -->
*IEEE International Conference on Acoustics, Speech and Signal Processing (****ICASSP****), poster, 2023*

Propose point flow as a novel point clouds descriptor to explore more dynamic information for human gait. Devise a dynamic frame sampling module to promote the efficiency of computation without deteriorating performance noticeably.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ISBI 2022</div><img src='images/isbi2022.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Active Index: An Integrated Index To Reveal Disrupted Brain Network Organizations Of Major Depressive Disorder Patients](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9761503)

Yu Fu$^{*}$, **Yanyan Huang$^{*}$**, Meng Niu, Le Xue, Shunjie Dong, Shunlin Guo, Junqiang Lei, Cheng Zhuo.

<!-- ***ISBI 2022*** -->
*IEEE International Symposium on Biomedical Imaging (****ISBI****), poster, 2022*

<!-- [**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
<!-- - For the first time discussed the differences between MDD and HC using both rich club and diverse club metrics and found the complementarity of them in analyzing brain networks.
- Proposed "active index", which defines a group of nodes that tend to be diversely distributed across communities while avoiding being a hub of a community. -->
For the first time discussed the differences between MDD and HC using both rich club and diverse club metrics and found the complementarity of them in analyzing brain networks. Proposed "active index", which defines a group of nodes that tend to be diversely distributed across communities while avoiding being a hub of a community.
</div>
</div>


<!-- - [HDNet: Hierarchical Dynamic Network for Gait Recognition using Millimeter-Wave Radar.](https://ieeexplore.ieee.org/abstract/document/10096835) **Yanyan Huang**, Yong Wang, Kun Shi, Chaojie Gu, Yu Fu, Cheng Zhuo, Zhiguo Shi. **ICASSP 2023** -->


- [MPGAN: Multi Pareto Generative Adversarial Network for the denoising and quantitative analysis of low-dose PET images of human brain](https://www.sciencedirect.com/science/article/abs/pii/S1361841524002317)

  Yu Fu, Shunjie Dong, **Yanyan Huang**, Meng Niu, Chao Ni, Lequan Yu, Kuangyu Shi, Zhijun Yao, Cheng Zhuo

  *Medical Image Analysis (****MIA****), 2024*


- [Sex-dependent nonlinear Granger connectivity patterns of brain aging in healthy population](https://www.sciencedirect.com/science/article/abs/pii/S0278584624001568)

  Yu Fu, Le Xue, Meng Niu, Yuanhang Gao, **Yanyan Huang**, Hong Zhang, Mei Tian, Cheng Zhuo.

  *Progress in Neuro-Psychopharmacology and Biological Psychiatry (****PNP****), 2024*


- [SFCNeXt: a simple fully convolutional network for effective brain age estimation with small sample size.](https://arxiv.org/abs/2305.18771)

  Yu Fu, **Yanyan Huang**, Shunjie Dong, Yalin Wang, Tianbai Yu, Meng Niu and Cheng Zhuo.

  *IEEE International Symposium on Biomedical Imaging (****ISBI****), poster, 2023*


  
- [AIGAN: Attention-encoding Integrated Generative Adversarial Network for the reconstruction of low-dose CT and low-dose PET images.](https://www.sciencedirect.com/science/article/pii/S1361841523000488?casa_token=97t2Om3H1rwAAAAA:eYqXt0tMZqKYd-hOaX4rNd1nIqgJ4s9Qy5-I5N9pffU4IJd0EDDVJNeEo4d1ybNfiDNfaftvgQ)

  Yu Fu, Shunjie Dong, Meng Niu, Le Xue, Hanning Guo, **Yanyan Huang**, Yuanfan Xu, Kuangyu Shi, Qianqian Yang, Yiyu Shi, Mei Tian, Cheng Zhuo.

  *Medical Image Analysis (****MIA****), 2023*

- [Altered nonlinear Granger causality interactions in the large-scale brain networks of patients with schizophrenia.](https://iopscience.iop.org/article/10.1088/1741-2552/acabe7/meta)
  
  Yu Fu, Meng Niu, Yuanhang Gao, Shunjie Dong, **Yanyan Huang**, Zhe Zhang and Cheng Zhuo.
  
  *Journal of Neural Engineering (****JNE****), 2022*

<!-- # üéñ Honors and Awards -->
# Honors and Awards
- *2023.05* Gold Medal (7/1165) in Kaggle ["Google - Isolated Sign Language Recognition"](https://www.kaggle.com/competitions/asl-signs) Competition.
- *2022.09* Gold Medal (4/1175) in Kaggle ["Hacking the Human Body"](https://www.kaggle.com/competitions/hubmap-organ-segmentation) Competition.
- *2022.05* Silver Medal (Top 2%) in Kaggle ["HM Recommendation"](https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations) Competition.
- *2020.06* People's Scholarship in Harbin Institute of Technology (Four consecutive years).
- *2018.10* National Scholarship in China (1.8%).
- *2018.07* The first prize of the Northeast Division of the "NXP" Cup Smart Car Competition.
- *2018.04* Meritorious Winner, Interdisciplinary Contest in Modeling (ICM), Consortium for Mathematics and Its Application.

<!-- # üìñ Educations -->
# Educations
- *2023.08 - Present*, Department of Statistics and Actuarial Science, The University of Hong Kong.
- *2020.09 - 2023.03*, College of Information Science and Electronic Engineering, Zhejiang University.
- *2016.09 - 2020.06*, School of Electronics and Information Engineering, Harbin Institite of Technology.

# Professional Activities
**Journal Reviewers**
- IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)

**Conference Reviewers**
- International Conference on Computer Vision (ICCV) 2023 CVAMD Workshop

<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

<!-- # üíª Internships
- *2023.04 - 2023.06*, [Baidu](https://github.com/), China. -->
